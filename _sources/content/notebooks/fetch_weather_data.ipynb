{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3485b0",
   "metadata": {},
   "source": [
    "# Historical weather data download from open-meteo.com\n",
    "\n",
    "This notebook downloads historical weather data for 10 medium to large urban\n",
    "areas in France from the Open Meteo Historical Forecast API. The data is\n",
    "saved in a Parquet file in the `datasets` folder.\n",
    "\n",
    "Since calling the API is slow and can reach rate limits quite easily with\n",
    "free accounts, we use a cache to avoid downloading the same data multiple\n",
    "times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extra dependencies when running this notebook in JupyterLite/Pyodide.\n",
    "%pip install -q openmeteo-requests retry-requests requests-cache ipyleaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ipyleaflet import Map, Marker\n",
    "import openmeteo_requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "from retry_requests import retry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5423bd",
   "metadata": {},
   "source": [
    "\n",
    "List of 10 medium to large urban areas with their GPS coordinates to cover\n",
    "most regions in France with a slight focus on most populated regions that\n",
    "are likely to drive electricity demand.\n",
    "\n",
    "The coordinates were suggested by Mistral's Le Chat. So better check on a map\n",
    "if they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\n",
    "    {\"name\": \"Paris\", \"latitude\": 48.8566, \"longitude\": 2.3522},\n",
    "    {\"name\": \"Lyon\", \"latitude\": 45.7640, \"longitude\": 4.8357},\n",
    "    {\"name\": \"Marseille\", \"latitude\": 43.2965, \"longitude\": 5.3698},\n",
    "    {\"name\": \"Toulouse\", \"latitude\": 43.6047, \"longitude\": 1.4442},\n",
    "    {\"name\": \"Lille\", \"latitude\": 50.6292, \"longitude\": 3.0573},\n",
    "    {\"name\": \"Limoges\", \"latitude\": 45.8336, \"longitude\": 1.2616},\n",
    "    {\"name\": \"Nantes\", \"latitude\": 47.2184, \"longitude\": -1.5536},\n",
    "    {\"name\": \"Strasbourg\", \"latitude\": 48.5734, \"longitude\": 7.7521},\n",
    "    {\"name\": \"Brest\", \"latitude\": 48.3904, \"longitude\": -4.4861},\n",
    "    {\"name\": \"Bayonne\", \"latitude\": 43.4833, \"longitude\": -1.4667},\n",
    "]\n",
    "\n",
    "map_center = [46.6034, 1.8883]  # Approximate center of France\n",
    "m = Map(center=map_center, zoom=6)\n",
    "for city in cities:\n",
    "    marker = Marker(location=(city[\"latitude\"], city[\"longitude\"]), title=city[\"name\"])\n",
    "    m.add_layer(marker)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0325ff16",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "Download weather data for each city. The data is downloaded from the Open\n",
    "Meteo Historical Forecast API, which provides historical weather data for\n",
    "free (with rate limits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weather_data(city):\n",
    "    session = requests_cache.CachedSession(\".cache\", expire_after=3600)\n",
    "    session = retry(session, retries=5, backoff_factor=0.1)\n",
    "    openmeteo = openmeteo_requests.Client(session=session)\n",
    "\n",
    "    # Make sure all required weather variables are listed here. The order of\n",
    "    # variables in hourly or daily is important to assign them correctly below.\n",
    "    url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": city[\"latitude\"],\n",
    "        \"longitude\": city[\"longitude\"],\n",
    "        \"start_date\": \"2021-01-01\",\n",
    "        \"end_date\": \"2025-05-31\",\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"cloud_cover\",\n",
    "            \"soil_moisture_1_to_3cm\",\n",
    "            \"relative_humidity_2m\",\n",
    "        ],\n",
    "        \"timezone\": \"GMT\",  # Use GMT to ease temporal joins.\n",
    "    }\n",
    "    response = openmeteo.weather_api(url, params=params)[0]\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "    hourly = response.Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "    hourly_precipitation = hourly.Variables(1).ValuesAsNumpy()\n",
    "    hourly_wind_speed_10m = hourly.Variables(2).ValuesAsNumpy()\n",
    "    hourly_cloud_cover = hourly.Variables(3).ValuesAsNumpy()\n",
    "    hourly_soil_moisture_1_to_3cm = hourly.Variables(4).ValuesAsNumpy()\n",
    "    hourly_relative_humidity_2m = hourly.Variables(5).ValuesAsNumpy()\n",
    "\n",
    "    hourly_data = {\n",
    "        \"time\": pd.date_range(\n",
    "            start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "            end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "            freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "            inclusive=\"left\",\n",
    "        )\n",
    "    }\n",
    "\n",
    "    hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "    hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "    hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n",
    "    hourly_data[\"cloud_cover\"] = hourly_cloud_cover\n",
    "    hourly_data[\"soil_moisture_1_to_3cm\"] = hourly_soil_moisture_1_to_3cm\n",
    "    hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "    return pd.DataFrame(data=hourly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26658640",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "Download weather data for each city and save it to a Parquet file in the\n",
    "`datasets` folder. The data is saved in a format that can be easily joined\n",
    "with the electricity load data. We use the Parquet format to save storage\n",
    "space and to speed up the loading time in the notebook. Parquet is also\n",
    "interesting because data types are not ambiguous contrary to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac711444",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = Path(\"../datasets\")\n",
    "for city in cities:\n",
    "    filepath = datasets_folder / f\"weather_{city['name'].lower()}.parquet\"\n",
    "    if filepath.exists():\n",
    "        print(f\"Weather data for {city['name']} already exists at {filepath}.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Downloading weather data for {city['name']}...\")\n",
    "    df = download_weather_data(city)\n",
    "    df.to_parquet(filepath, index=False)\n",
    "    print(f\"Weather data for {city['name']} saved to {filepath}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22714b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
